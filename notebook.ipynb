{"cells":[{"source":"# Build a Retrieval Augmented Generation (RAG) App","metadata":{},"cell_type":"markdown","id":"abd666df-97b0-4f0e-b110-142ce50ef61e"},{"source":"![RAG Indexing](https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png)","metadata":{},"cell_type":"markdown","id":"2196e32b-e99a-4a79-bebb-5db6899ee915"},{"source":"# Installation \nThis tutorial requires the `langchain` dependency.","metadata":{},"cell_type":"markdown","id":"cbd5f8da-9cda-4cef-b5cf-7fe1d06afa7e"},{"source":"%%capture\n%pip install --quiet --upgrade langchain langchain-community langchain-chroma","metadata":{"executionCancelledAt":null,"executionTime":9329,"lastExecutedAt":1732132492147,"lastExecutedByKernel":"b81c6160-f8bd-44f7-9ad5-f43c91bd3c0f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"%%capture\n%pip install --quiet --upgrade langchain langchain-community langchain-chroma","outputsMetadata":{"0":{"height":479,"type":"stream"}}},"cell_type":"code","id":"548c3b6e-ac5f-4f48-824c-783aaeb47e49","outputs":[],"execution_count":1},{"source":"%%capture\n%pip install -qU langchain-openai","metadata":{"executionCancelledAt":null,"executionTime":3546,"lastExecutedAt":1732132495695,"lastExecutedByKernel":"b81c6160-f8bd-44f7-9ad5-f43c91bd3c0f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"%%capture\n%pip install -qU langchain-openai","outputsMetadata":{"0":{"height":332,"type":"stream"}}},"cell_type":"code","id":"2bff181b-8ebb-415b-ab22-8141b9d0a580","outputs":[],"execution_count":2},{"source":"# Data Preprocessing Workflow","metadata":{},"cell_type":"markdown","id":"f1068e4f-4bd6-48a3-9775-bfcdc2fc9f11"},{"source":"transformer = {\n    \"transformer_id\":1,\n    \"Customer\": \"Honda Automobile (Thailand) Co., Ltd.\",\n    \"Location\": \"Ayutthaya Sub.1\",\n    \"Technical Data\": {\n        \"Manufacture\": \"DAIHEN\",\n        \"Type\": \"PP0318B02\",\n        \"Rated voltage\": \"115\",\n        \"Rated frequency\": \"50\",\n        \"Rated power\": \"20000/25000\"\n    },\n    \"On-Load Tap Changer\": {\n        \"Manufacture\": \"MR\",\n        \"Type\": \"Vlll 200D-123/76-1019 3W\",\n        \"Rated voltage\": \"400/230\",\n        \"Rated current\": \"161\"\n    }\n}","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1732132495748,"lastExecutedByKernel":"b81c6160-f8bd-44f7-9ad5-f43c91bd3c0f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"transformer = {\n    \"transformer_id\":1,\n    \"Customer\": \"Honda Automobile (Thailand) Co., Ltd.\",\n    \"Location\": \"Ayutthaya Sub.1\",\n    \"Technical Data\": {\n        \"Manufacture\": \"DAIHEN\",\n        \"Type\": \"PP0318B02\",\n        \"Rated voltage\": \"115\",\n        \"Rated frequency\": \"50\",\n        \"Rated power\": \"20000/25000\"\n    },\n    \"On-Load Tap Changer\": {\n        \"Manufacture\": \"MR\",\n        \"Type\": \"Vlll 200D-123/76-1019 3W\",\n        \"Rated voltage\": \"400/230\",\n        \"Rated current\": \"161\"\n    }\n}"},"cell_type":"code","id":"1a45a36a-1535-41ce-b3f4-4efb53543dc0","outputs":[],"execution_count":3},{"source":"import pandas as pd\nfrom sqlalchemy import create_engine\n\n# Path to your Excel file\nfile_path = 'data/data_poc.xlsx'\n\n# SQLite database setup\nengine = create_engine('sqlite:///transformer_data.db')\n\n# Load the Excel file\nxls = pd.ExcelFile(file_path)\n\n# Process each sheet and save to SQLite\nfor sheet_name in xls.sheet_names:\n    # Load each sheet into a DataFrame\n    df = pd.read_excel(file_path, sheet_name=sheet_name)\n    \n    # Add transformer_id column\n    df['transformer_id'] = 1\n\n    # Clean the DataFrame (remove completely empty rows/columns)\n    df = df.dropna(how='all', axis=0)  # Remove empty rows\n    df = df.dropna(how='all', axis=1)  # Remove empty columns\n\n    # Save the DataFrame to SQLite\n    table_name = sheet_name.replace(\" \", \"_\").lower()  # Normalize table name\n    df.to_sql(table_name, engine, index=False, if_exists='replace')\n\nprint(\"Data from all sheets has been successfully saved to the SQLite database.\")\n","metadata":{"executionCancelledAt":null,"executionTime":9367,"lastExecutedAt":1732132505115,"lastExecutedByKernel":"b81c6160-f8bd-44f7-9ad5-f43c91bd3c0f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom sqlalchemy import create_engine\n\n# Path to your Excel file\nfile_path = 'data/data_poc.xlsx'\n\n# SQLite database setup\nengine = create_engine('sqlite:///transformer_data.db')\n\n# Load the Excel file\nxls = pd.ExcelFile(file_path)\n\n# Process each sheet and save to SQLite\nfor sheet_name in xls.sheet_names:\n    # Load each sheet into a DataFrame\n    df = pd.read_excel(file_path, sheet_name=sheet_name)\n    \n    # Add transformer_id column\n    df['transformer_id'] = 1\n\n    # Clean the DataFrame (remove completely empty rows/columns)\n    df = df.dropna(how='all', axis=0)  # Remove empty rows\n    df = df.dropna(how='all', axis=1)  # Remove empty columns\n\n    # Save the DataFrame to SQLite\n    table_name = sheet_name.replace(\" \", \"_\").lower()  # Normalize table name\n    df.to_sql(table_name, engine, index=False, if_exists='replace')\n\nprint(\"Data from all sheets has been successfully saved to the SQLite database.\")\n","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"bfaa565f-966b-41d9-b8cb-e569febc62aa","outputs":[{"output_type":"stream","name":"stdout","text":"Data from all sheets has been successfully saved to the SQLite database.\n"}],"execution_count":4},{"source":"import sqlite3\n\n# Path to your SQLite database\ndb_path = 'transformer_data.db'\n\n# Connect to the database\nconn = sqlite3.connect(db_path)\n\n# Query to list all tables\nquery = \"SELECT name FROM sqlite_master WHERE type='table';\"\ncursor = conn.cursor()\ncursor.execute(query)\n\n# Fetch all table names\ntables = cursor.fetchall()\n\n# Print table names\nprint(\"Tables in the database:\")\nfor table in tables:\n    print(table[0])\n\n# Close the connection\nconn.close()\n","metadata":{"executionCancelledAt":null,"executionTime":63,"lastExecutedAt":1732132505178,"lastExecutedByKernel":"b81c6160-f8bd-44f7-9ad5-f43c91bd3c0f","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import sqlite3\n\n# Path to your SQLite database\ndb_path = 'transformer_data.db'\n\n# Connect to the database\nconn = sqlite3.connect(db_path)\n\n# Query to list all tables\nquery = \"SELECT name FROM sqlite_master WHERE type='table';\"\ncursor = conn.cursor()\ncursor.execute(query)\n\n# Fetch all table names\ntables = cursor.fetchall()\n\n# Print table names\nprint(\"Tables in the database:\")\nfor table in tables:\n    print(table[0])\n\n# Close the connection\nconn.close()\n","outputsMetadata":{"0":{"height":290,"type":"stream"}}},"cell_type":"code","id":"87487665-265a-495b-b26b-5cd0c4c6e059","outputs":[{"output_type":"stream","name":"stdout","text":"Tables in the database:\nt1\nt2\nt3\nt4\nt5\nt6\nt7\nt8\nt9\nt10\nt11\nt12\n"}],"execution_count":5},{"source":"import os\nimport sqlite3\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.chains import RetrievalQA\nfrom langchain.llms import OpenAI\nfrom langchain.prompts import PromptTemplate\n\n# Set up OpenAI API key\n# os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\"  # Replace with your OpenAI API Key\n\n# Connect to the SQLite database\ndb_path = \"transformer_data.db\"  # Path to your SQLite database\nconn = sqlite3.connect(db_path)\n\n# Function to load data from SQLite and create documents\ndef load_transformer_data(transformer_id):\n    query = f\"SELECT * FROM t1 WHERE transformer_id = {transformer_id}\"  # Adjust table name as needed\n    df = pd.read_sql_query(query, conn)\n\n    # Combine rows into a single document with context\n    transformer_docs = []\n    for _, row in df.iterrows():\n        doc_content = f\"\"\"\n        Transformer ID: {transformer_id}\n        Year: {row['year']}\n        HV to GND: {row.get('HV to GND', 'N/A')}\n        LV to GND: {row.get('LV to GND', 'N/A')}\n        HV to LV: {row.get('HV to LV', 'N/A')}\n        Measuring Type: {row.get('measuring_type', 'N/A')}\n        \"\"\"\n        transformer_docs.append(doc_content)\n    return transformer_docs\n\n# Load data for transformer_id = 1\ntransformer_id = 1\ndocs = load_transformer_data(transformer_id)\n\n# Split documents into chunks\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\nsplits = text_splitter.split_text(\"\\n\".join(docs))\n\n# Generate embeddings and store in Chroma\nembeddings = OpenAIEmbeddings()\nvectorstore = Chroma.from_texts(splits, embeddings)\n\n# Set up the retriever\nretriever = vectorstore.as_retriever()\n\n# Define the RAG pipeline\nllm = OpenAI(temperature=0, model=\"gpt-4o\")\nprompt_template = \"\"\"\nYou are a transformer maintenance assistant. Based on the following transformer data:\n\n{context}\n\nAnswer the following question:\n{question}\n\"\"\"\nprompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n\nqa_chain = RetrievalQA(llm=llm, retriever=retriever, return_source_documents=True, prompt=prompt)\n\n# Query the RAG system\nquestion = \"What was the HV to GND value for 2561?\"\nresponse = qa_chain.run(question)\n\n# Display the response\nprint(\"Response:\")\nprint(response)\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":164,"type":"stream"}}},"cell_type":"code","id":"f32c37f6-b169-4391-9d71-c21340e8b2f8","outputs":[{"output_type":"stream","name":"stderr","text":"/tmp/ipykernel_3976/1322626330.py:45: LangChainDeprecationWarning:\n\nThe class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n\n"},{"output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m splits \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(docs))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Generate embeddings and store in Chroma\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_texts(splits, embeddings)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Set up the retriever\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     emit_warning()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/main.py:212\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    211\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    214\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    218\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m     )\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error"],"ename":"ValidationError","evalue":"1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.9/v/value_error"}],"execution_count":4},{"source":"import getpass\nimport os\nimport bs4\nos.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\nfrom langchain import hub\nfrom langchain_chroma import Chroma\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_openai import ChatOpenAI\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\n# Load, chunk and index the contents of the blog.\nloader = WebBaseLoader(\n    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n    bs_kwargs=dict(\n        parse_only=bs4.SoupStrainer(\n            class_=(\"post-content\", \"post-title\", \"post-header\")\n        )\n    ),\n)\ndocs = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\nsplits = text_splitter.split_documents(docs)\nvectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n\n# Retrieve and generate using the relevant snippets of the blog.\nretriever = vectorstore.as_retriever()\nprompt = hub.pull(\"rlm/rag-prompt\")\n\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nrag_chain.invoke(\"What is Task Decomposition?\")","metadata":{"executionCancelledAt":1732132506924,"executionTime":367,"lastExecutedAt":1732131530767,"lastExecutedByKernel":"878ed515-3c52-4624-9b2e-6b0611ba457a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import getpass\nimport os\nimport bs4\nos.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\nfrom langchain import hub\nfrom langchain_chroma import Chroma\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_openai import ChatOpenAI\nllm = ChatOpenAI(model=\"gpt-4o-mini\")\n# Load, chunk and index the contents of the blog.\nloader = WebBaseLoader(\n    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n    bs_kwargs=dict(\n        parse_only=bs4.SoupStrainer(\n            class_=(\"post-content\", \"post-title\", \"post-header\")\n        )\n    ),\n)\ndocs = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\nsplits = text_splitter.split_documents(docs)\nvectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n\n# Retrieve and generate using the relevant snippets of the blog.\nretriever = vectorstore.as_retriever()\nprompt = hub.pull(\"rlm/rag-prompt\")\n\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nrag_chain.invoke(\"What is Task Decomposition?\")"},"cell_type":"code","id":"2d86d91d-0753-4417-a42a-35b36c5ce2eb","outputs":[{"output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnablePassthrough\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_openai/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_openai/chat_models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mazure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAzureChatOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_openai/chat_models/azure.py:21\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     Any,\n\u001b[1;32m      9\u001b[0m     Awaitable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     Union,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage_models\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LangSmithParams\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMessage\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatResult\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py)"],"ename":"ImportError","evalue":"cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py)"}],"execution_count":null},{"source":"# cleanup\nvectorstore.delete_collection()","metadata":{"executionCancelledAt":1732132506926,"executionTime":55,"lastExecutedAt":1732131556609,"lastExecutedByKernel":"878ed515-3c52-4624-9b2e-6b0611ba457a","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# cleanup\nvectorstore.delete_collection()"},"cell_type":"code","id":"4d26ece6-07da-4703-88be-a879648d05e0","outputs":[],"execution_count":15}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}